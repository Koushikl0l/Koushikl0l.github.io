{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Overview\n",
        "\n",
        "\n",
        "In this example, you will train an autoencoder to detect anomalies on the [ECG5000 dataset](http://www.timeseriesclassification.com/description.php?Dataset=ECG5000). This dataset contains 5,000 [Electrocardiograms](https://en.wikipedia.org/wiki/Electrocardiography), each with 140 data points. You will use a simplified version of the dataset, where each example has been labeled either `0` (corresponding to an abnormal rhythm), or `1` (corresponding to a normal rhythm). You are interested in identifying the abnormal rhythms.\n",
        "\n",
        "Note: This is a labeled dataset, so you could phrase this as a supervised learning problem. The goal of this example is to illustrate anomaly detection concepts you can apply to larger datasets, where you do not have labels available (for example, if you had many thousands of normal rhythms, and only a small number of abnormal rhythms).\n",
        "\n",
        "How will you detect anomalies using an autoencoder? Recall that an autoencoder is trained to minimize reconstruction error. You will train an autoencoder on the normal rhythms only, then use it to reconstruct all the data. Our hypothesis is that the abnormal rhythms will have higher reconstruction error. You will then classify a rhythm as an anomaly if the reconstruction error surpasses a fixed threshold."
      ],
      "metadata": {
        "id": "MrdtHvFKq9-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "LimvnlZ4xJ4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load ECG data"
      ],
      "metadata": {
        "id": "ua3tgSrSrZFw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5Zd44a0qxss"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\n",
        "raw_data = dataframe.values\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The last element contains the labels\n",
        "labels = raw_data[:, -1]\n",
        "\n",
        "# The other data points are the electrocadriogram data\n",
        "data = raw_data[:, 0:-1]\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    data, labels, test_size=0.2, random_state=21\n",
        ")"
      ],
      "metadata": {
        "id": "l2G8ZwlFrfkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalize [0,1]"
      ],
      "metadata": {
        "id": "K3cb5iFerv0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_val = tf.reduce_min(train_data)\n",
        "max_val = tf.reduce_max(train_data)\n",
        "\n",
        "train_data = (train_data - min_val) / (max_val - min_val)\n",
        "test_data = (test_data - min_val) / (max_val - min_val)\n",
        "\n",
        "train_data = tf.cast(train_data, tf.float32)\n",
        "test_data = tf.cast(test_data, tf.float32)"
      ],
      "metadata": {
        "id": "h4J01Ebqrglv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will train the autoencoder using only the normal rhythms, which are labeled in this dataset as `1`. Separate the normal rhythms from the abnormal rhythms."
      ],
      "metadata": {
        "id": "8ew5D54qskiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_labels.astype(bool)\n",
        "test_labels = test_labels.astype(bool)\n",
        "\n",
        "normal_train_data = train_data[train_labels]\n",
        "normal_test_data = test_data[test_labels]\n",
        "\n",
        "anomalous_train_data = train_data[~train_labels]\n",
        "anomalous_test_data = test_data[~test_labels]"
      ],
      "metadata": {
        "id": "pQlWNlOgsfiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot a normal ECG."
      ],
      "metadata": {
        "id": "FZS1t8tust5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.grid()\n",
        "plt.plot(np.arange(140), normal_train_data[0])\n",
        "plt.title(\"A Normal ECG\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KVAp83jGssyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot an anomalous ECG."
      ],
      "metadata": {
        "id": "boojP8dysvI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.grid()\n",
        "plt.plot(np.arange(140), anomalous_train_data[0])\n",
        "plt.title(\"An Anomalous ECG\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hC8Jrnw6stGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the model"
      ],
      "metadata": {
        "id": "Tm7o3yr_tWfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AnomalyDetector(Model):\n",
        "  def __init__(self):\n",
        "    super(AnomalyDetector, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Dense(32, activation=\"relu\"),\n",
        "      layers.Dense(16, activation=\"relu\"),\n",
        "      layers.Dense(8, activation=\"relu\")])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(16, activation=\"relu\"),\n",
        "      layers.Dense(32, activation=\"relu\"),\n",
        "      layers.Dense(140, activation=\"sigmoid\")])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = AnomalyDetector()"
      ],
      "metadata": {
        "id": "8411SzNbtSJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='mae')"
      ],
      "metadata": {
        "id": "JGs4gqe6tYWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the autoencoder is trained using only the normal ECGs, but is evaluated using the full test set."
      ],
      "metadata": {
        "id": "TYGYXE5Etfv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(normal_train_data, normal_train_data,\n",
        "          epochs=20,\n",
        "          batch_size=512,\n",
        "          validation_data=(test_data, test_data),\n",
        "          shuffle=True)"
      ],
      "metadata": {
        "id": "eCjbYGCUtegv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "p2SSApfnt3VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will soon classify an ECG as anomalous if the reconstruction error is greater than one standard deviation from the normal training examples. First, let's plot a normal ECG from the training set, the reconstruction after it's encoded and decoded by the autoencoder, and the reconstruction error."
      ],
      "metadata": {
        "id": "YUGNFMLBt6Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = autoencoder.encoder(normal_test_data).numpy()\n",
        "decoded_data = autoencoder.decoder(encoded_data).numpy()\n",
        "\n",
        "plt.plot(normal_test_data[0], 'b')\n",
        "plt.plot(decoded_data[0], 'r')\n",
        "plt.fill_between(np.arange(140), decoded_data[0], normal_test_data[0], color='lightcoral')\n",
        "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JVJwpvcIt6rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a similar plot, this time for an anomalous test example."
      ],
      "metadata": {
        "id": "qR89U6xUuEJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = autoencoder.encoder(anomalous_test_data).numpy()\n",
        "decoded_data = autoencoder.decoder(encoded_data).numpy()\n",
        "\n",
        "plt.plot(anomalous_test_data[0], 'b')\n",
        "plt.plot(decoded_data[0], 'r')\n",
        "plt.fill_between(np.arange(140), decoded_data[0], anomalous_test_data[0], color='lightcoral')\n",
        "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gVIbHaWguEr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect anomalies by calculating whether the reconstruction loss is greater than a fixed threshold. In this tutorial, you will calculate the mean average error for normal examples from the training set, then classify future examples as anomalous if the reconstruction error is higher than one standard deviation from the training set."
      ],
      "metadata": {
        "id": "C6kNGWJhujQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the reconstruction error on normal ECGs from the training set"
      ],
      "metadata": {
        "id": "a0WyTQ6nulWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = autoencoder.predict(normal_train_data)\n",
        "train_loss = tf.keras.losses.mae(reconstructions, normal_train_data)\n",
        "\n",
        "plt.hist(train_loss[None,:], bins=50)\n",
        "plt.xlabel(\"Train loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QbT2NQjKukUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose a threshold value that is one standard deviations above the mean."
      ],
      "metadata": {
        "id": "u8sFHU__uuqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.mean(train_loss) + np.std(train_loss)\n",
        "print(\"Threshold: \", threshold)"
      ],
      "metadata": {
        "id": "mpOUrFAmuvoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: There are other strategies you could use to select a threshold value above which test examples should be classified as anomalous, the correct approach will depend on your dataset. You can learn more with the links at the end of this tutorial."
      ],
      "metadata": {
        "id": "HXeCfGkgu4yO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you examine the reconstruction error for the anomalous examples in the test set, you'll notice most have greater reconstruction error than the threshold. By varing the threshold, you can adjust the precision and recall of your classifier."
      ],
      "metadata": {
        "id": "CpxT0s4Su-zb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xqKW7v_nu38v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = autoencoder.predict(anomalous_test_data)\n",
        "test_loss = tf.keras.losses.mae(reconstructions, anomalous_test_data)\n",
        "\n",
        "plt.hist(test_loss[None, :], bins=50)\n",
        "plt.xlabel(\"Test loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S8kGOMaUu3en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classify an ECG as an anomaly if the reconstruction error is greater than the threshold."
      ],
      "metadata": {
        "id": "eBMzSQfyvJaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, data, threshold):\n",
        "  reconstructions = model(data)\n",
        "  loss = tf.keras.losses.mae(reconstructions, data)\n",
        "  return tf.math.less(loss, threshold)\n",
        "\n",
        "def print_stats(predictions, labels):\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
        "  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
        "  print(\"Recall = {}\".format(recall_score(labels, predictions)))"
      ],
      "metadata": {
        "id": "oobd41CzvMl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict(autoencoder, test_data, threshold)\n",
        "print_stats(preds, test_labels)"
      ],
      "metadata": {
        "id": "E8TVv-jtvPts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "\n",
        "To learn more about anomaly detection with autoencoders, check out this excellent [interactive example](https://anomagram.fastforwardlabs.com/#/) built with TensorFlow.js by Victor Dibia. For a real-world use case, you can learn how [Airbus Detects Anomalies in ISS Telemetry Data](https://blog.tensorflow.org/2020/04/how-airbus-detects-anomalies-iss-telemetry-data-tfx.html) using TensorFlow. To learn more about the basics, consider reading this [blog post](https://blog.keras.io/building-autoencoders-in-keras.html) by François Chollet. For more details, check out chapter 14 from [Deep Learning](https://www.deeplearningbook.org/) by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.\n"
      ],
      "metadata": {
        "id": "zfDefBW5vUOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D-_nDf4BvU26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2207dd99"
      },
      "source": [
        "# Task\n",
        "Create a blog post draft based on the provided notebook \"notebook.ipynb\" that includes notes, images, and information about the anomaly detection approach, model results (accuracy, precision, recall), and next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e67447dd"
      },
      "source": [
        "## Extract and summarize key concepts\n",
        "\n",
        "### Subtask:\n",
        "Read the markdown cells, focusing on the introduction and explanation of the anomaly detection approach. Summarize the core ideas and methodology presented.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec055ec3"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to summarize the introduction and explanation of the anomaly detection approach based on the markdown cells. I will read the relevant markdown cells and extract the core ideas to form the summary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21c9d98e"
      },
      "source": [
        "# Read the markdown cells and summarize the anomaly detection approach.\n",
        "# Based on cell_id: MrdtHvFKq9-2, ua3tgSrSrZFw, K3cb5iFerv0e, 8ew5D54qskiw, C6kNGWJhujQK, a0WyTQ6nulWI, u8sFHU__uuqo, CpxT0s4Su-zb, eBMzSQfyvJaT, zfDefBW5vUOJ\n",
        "\n",
        "summary = \"\"\"\n",
        "This blog post will demonstrate how to use an autoencoder to detect anomalies in the ECG5000 dataset.\n",
        "The dataset contains 5,000 Electrocardiograms, each with 140 data points, labeled as either normal (1) or abnormal (0).\n",
        "The goal is to identify the abnormal rhythms, treating this as an unsupervised anomaly detection problem despite having labels, to illustrate a method applicable when labels are scarce.\n",
        "\n",
        "The approach utilizes an autoencoder, a type of neural network trained to reconstruct its input.\n",
        "The autoencoder is specifically trained *only* on the normal ECG rhythms from the dataset.\n",
        "The core hypothesis is that when presented with an abnormal rhythm, the autoencoder, having only learned to reconstruct normal patterns, will produce a higher reconstruction error compared to normal rhythms.\n",
        "\n",
        "Anomaly detection is then performed by calculating the reconstruction error for each ECG.\n",
        "A fixed threshold is determined based on the reconstruction error of the normal training data (specifically, one standard deviation above the mean of the training loss).\n",
        "ECGs with a reconstruction error exceeding this threshold are classified as anomalous.\n",
        "\"\"\"\n",
        "\n",
        "print(summary)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}