<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Robust Fusion and Contrastive Learning for Multimodal AQI Regression</title>
  <style>
    body {
      font-family: "Times New Roman", Times, serif;
      font-size: 14px;
      margin: 0;
      padding: 0;
      background-color: #fff;
      color: #000;
    }
    .container {
      width: 90%;
      max-width: 1100px;
      margin: 40px auto;
    }
    .title {
      text-align: center;
      font-size: 22px;
      font-weight: bold;
    }
    .author {
      text-align: center;
      font-size: 14px;
      margin-bottom: 20px;
    }
    .section {
      margin-bottom: 30px;
    }
    .abstract-box {
      border: 1px dashed #999;
      padding: 15px;
      margin-bottom: 20px;
    }
    .keywords {
      margin-top: -10px;
      margin-bottom: 30px;
    }
    .columns {
      display: flex;
      gap: 20px;
    }
    .column {
      flex: 1;
    }
    .figure {
      text-align: center;
      font-size: 12px;
      margin-top: 10px;
      margin-bottom: 20px;
    }
    .image-grid {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 10px;
      margin: 20px 0;
    }
    .image-grid img {
      width: 100%;
      border: 1px solid #999;
      border-radius: 4px;
    }
    .caption {
      text-align: center;
      font-size: 11px;
      color: #444;
    }
    h2 {
      font-size: 16px;
      margin: 15px 0 5px;
    }
    .dashed-box {
      border: 1.5px dashed #666;
      padding: 10px;
      margin-bottom: 20px;
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="title">
      Robust Fusion and Contrastive Learning for Multimodal AQI Regression
    </div>
    <div class="author">
      FirstName LastName <br>
      Department of Computer Science, University Name <br>
      email@example.com
    </div>

    <div class="abstract-box">
      <strong>ABSTRACT</strong>
      <p>
        A multimodal approach for predicting Air Quality Index (AQI) by integrating numerical and image data.
        A precision-integrated numerical branch and an image encoder using EfficientNetB0 extract features.
        Cross-modal attention is utilized to enhance interaction between modalities, followed by multi-head self-attention
        and a gated fusion mechanism for robust integration. A contrastive loss function is incorporated during training
        to align numerical and image embeddings, leading to state-of-the-art performance in AQI regression from multiple data sources.
      </p>
    </div>

    <div class="keywords">
      <strong>KEYWORDS</strong>: Multimodal learning, AQI regression, contrastive loss, robust fusion
    </div>

    <div class="columns">
      <div class="column">
        <div class="section">
          <h2>1 INTRODUCTION</h2>
          <p>
            AQI prediction requires integrating heterogeneous data sources. Traditional unimodal models often
            fail to generalize. Multimodal fusion leverages both numerical sensor data and visual cues from
            images (e.g., sky color) to better estimate AQI. Our work utilizes cross-modal attention,
            multi-head self-attention, gated fusion, and contrastive learning to create a unified prediction model.
          </p>
        </div>

        <div class="section dashed-box">
          <h2>3 NUMERICAL AND SELF-ATTENTION MECHANISMS</h2>
          <p>
            The numerical branch passes sensor data through dense layers. Self-attention learns internal dependencies.
            Gated fusion combines features from modalities after alignment using cross-modal attention.
          </p>
        </div>
      </div>

      <div class="column">
        <div class="section dashed-box">
          <h2>2 CROSS-MODAL AND SELF-ATTENTION MECHANISMS</h2>
          <p>
            Cross-modal attention aligns the embeddings from image and sensor data. It transforms the
            query-key-value projections and feeds them into a self-attention block for joint feature refinement.
          </p>
        </div>

        <div class="figure">
          <strong>Figure 1: Cross-Modal AQI Regression Architecture</strong>
          <div class="image-grid">
            <div>
              <img src="images/box1_numerical_branch.png" alt="Box 1">
              <div class="caption">1. Numerical Branch</div>
            </div>
            <div>
              <img src="images/box2_image_branch.png" alt="Box 2">
              <div class="caption">2. Image Branch</div>
            </div>
            <div>
              <img src="images/box3_attention.png" alt="Box 3">
              <div class="caption">3. Cross-Modal Attention</div>
            </div>
            <div>
              <img src="images/box4_self_attention.png" alt="Box 4">
              <div class="caption">4. Self-Attention</div>
            </div>
            <div>
              <img src="images/box5_gated_fusion.png" alt="Box 5">
              <div class="caption">5. Gated Fusion</div>
            </div>
            <div>
              <img src="images/box6_output.png" alt="Box 6">
              <div class="caption">6. Final Output</div>
            </div>
          </div>
        </div>
      </div>
    </div>

  </div>
</body>
</html>
